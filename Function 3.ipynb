{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f98ed2b9-87f7-4834-9e2e-1e64e6c5f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79830ed0-db06-43ef-8963-5457e4085470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.load(r'C:\\Users\\xdb13122\\Desktop\\ML Course\\capstone project\\initial_data\\function_3\\initial_inputs.npy')\n",
    "Y1 = np.load(r'C:\\Users\\xdb13122\\Desktop\\ML Course\\capstone project\\initial_data\\function_3\\initial_outputs.npy')\n",
    "X2 = np.load(r'C:\\Users\\xdb13122\\Desktop\\ML Course\\capstone project\\initial_data2\\function_3\\initial_inputs.npy')\n",
    "Y2 = np.load(r'C:\\Users\\xdb13122\\Desktop\\ML Course\\capstone project\\initial_data2\\function_3\\initial_outputs.npy')\n",
    "X = np.concatenate((X1, X2), axis=0)\n",
    "Y = np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c26de07c-7267-4f23-8c76-fea8f44dd79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17152521, 0.34391687, 0.2487372 ],\n",
       "       [0.24211446, 0.64407427, 0.27243281],\n",
       "       [0.53490572, 0.39850092, 0.17338873],\n",
       "       [0.49258141, 0.61159319, 0.34017639],\n",
       "       [0.13462167, 0.21991724, 0.45820622],\n",
       "       [0.34552327, 0.94135983, 0.26936348],\n",
       "       [0.15183663, 0.43999062, 0.99088187],\n",
       "       [0.64550284, 0.39714294, 0.91977134],\n",
       "       [0.74691195, 0.28419631, 0.22629985],\n",
       "       [0.17047699, 0.6970324 , 0.14916943],\n",
       "       [0.22054934, 0.29782524, 0.34355534],\n",
       "       [0.66601366, 0.67198515, 0.2462953 ],\n",
       "       [0.04680895, 0.23136024, 0.77061759],\n",
       "       [0.60009728, 0.72513573, 0.06608864],\n",
       "       [0.96599485, 0.86111969, 0.56682913],\n",
       "       [0.16569979, 0.25685582, 0.65469   ],\n",
       "       [0.65099632, 0.42417272, 0.52674437],\n",
       "       [0.10601263, 0.24333177, 0.65025654],\n",
       "       [0.35216426, 0.10580766, 0.06546785],\n",
       "       [0.829086  , 0.4393692 , 0.20713429],\n",
       "       [0.80489315, 0.31206954, 0.24371441],\n",
       "       [0.46204056, 0.12939599, 0.83858636],\n",
       "       [0.82217052, 0.46650685, 0.54929183],\n",
       "       [0.98514841, 0.72088289, 0.77643975],\n",
       "       [0.18674264, 0.60674065, 0.66958022],\n",
       "       [0.28810255, 0.70297378, 0.89849626],\n",
       "       [0.08742747, 0.26673553, 0.30128017],\n",
       "       [0.87436053, 0.86753817, 0.89436325],\n",
       "       [0.70350412, 0.18532319, 0.81992293],\n",
       "       [0.57579775, 0.32285284, 0.53417744]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c51e35bc-c72d-47fa-80e7-ae6a0dadb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = np.array([[0.864411, 0.276113, 0.874451], [0.791462, 0.581073, 0.615003], [0.699532, 0.529816, 0.4750162],[0.699532, 0.529816, 0.475016], [0.788473, 0.982177, 0.253373], [0.228546, 0.599028, 0.31107]])\n",
    "X = np.concatenate((X, new_row), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae37b7f4-bf0d-42f9-9eed-8a1b729f8dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17152521, 0.34391687, 0.2487372 ],\n",
       "       [0.24211446, 0.64407427, 0.27243281],\n",
       "       [0.53490572, 0.39850092, 0.17338873],\n",
       "       [0.49258141, 0.61159319, 0.34017639],\n",
       "       [0.13462167, 0.21991724, 0.45820622],\n",
       "       [0.34552327, 0.94135983, 0.26936348],\n",
       "       [0.15183663, 0.43999062, 0.99088187],\n",
       "       [0.64550284, 0.39714294, 0.91977134],\n",
       "       [0.74691195, 0.28419631, 0.22629985],\n",
       "       [0.17047699, 0.6970324 , 0.14916943],\n",
       "       [0.22054934, 0.29782524, 0.34355534],\n",
       "       [0.66601366, 0.67198515, 0.2462953 ],\n",
       "       [0.04680895, 0.23136024, 0.77061759],\n",
       "       [0.60009728, 0.72513573, 0.06608864],\n",
       "       [0.96599485, 0.86111969, 0.56682913],\n",
       "       [0.16569979, 0.25685582, 0.65469   ],\n",
       "       [0.65099632, 0.42417272, 0.52674437],\n",
       "       [0.10601263, 0.24333177, 0.65025654],\n",
       "       [0.35216426, 0.10580766, 0.06546785],\n",
       "       [0.829086  , 0.4393692 , 0.20713429],\n",
       "       [0.80489315, 0.31206954, 0.24371441],\n",
       "       [0.46204056, 0.12939599, 0.83858636],\n",
       "       [0.82217052, 0.46650685, 0.54929183],\n",
       "       [0.98514841, 0.72088289, 0.77643975],\n",
       "       [0.18674264, 0.60674065, 0.66958022],\n",
       "       [0.28810255, 0.70297378, 0.89849626],\n",
       "       [0.08742747, 0.26673553, 0.30128017],\n",
       "       [0.87436053, 0.86753817, 0.89436325],\n",
       "       [0.70350412, 0.18532319, 0.81992293],\n",
       "       [0.57579775, 0.32285284, 0.53417744],\n",
       "       [0.864411  , 0.276113  , 0.874451  ],\n",
       "       [0.791462  , 0.581073  , 0.615003  ],\n",
       "       [0.699532  , 0.529816  , 0.4750162 ],\n",
       "       [0.699532  , 0.529816  , 0.475016  ],\n",
       "       [0.788473  , 0.982177  , 0.253373  ],\n",
       "       [0.228546  , 0.599028  , 0.31107   ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "003a53b4-46e3-40d9-905f-59d46813d69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1121222 , -0.08796286, -0.11141465, -0.03483531, -0.04800758,\n",
       "       -0.11062091, -0.39892551, -0.11386851, -0.13146061, -0.09418956,\n",
       "       -0.04694741, -0.10596504, -0.11804826, -0.03637783, -0.05675837,\n",
       "       -0.12809391, -0.03103939, -0.1172756 , -0.07944403, -0.14258557,\n",
       "       -0.11962132, -0.06119926, -0.03435924, -0.0876973 , -0.11502216,\n",
       "       -0.07478879, -0.10441561, -0.08945485, -0.08760022, -0.02514614])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80cf7628-b3ff-4a32-b7fc-77033ba4234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = np.array([-0.05412569940370686, -0.06319905645357159, -0.0005480369123123483, -0.0005480369123123483, -0.16369976998517352, -0.07402727571803658])\n",
    "Y = np.concatenate((Y, new_row), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa378837-787e-4d51-aebd-8ba393059163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1121222 , -0.08796286, -0.11141465, -0.03483531, -0.04800758,\n",
       "       -0.11062091, -0.39892551, -0.11386851, -0.13146061, -0.09418956,\n",
       "       -0.04694741, -0.10596504, -0.11804826, -0.03637783, -0.05675837,\n",
       "       -0.12809391, -0.03103939, -0.1172756 , -0.07944403, -0.14258557,\n",
       "       -0.11962132, -0.06119926, -0.03435924, -0.0876973 , -0.11502216,\n",
       "       -0.07478879, -0.10441561, -0.08945485, -0.08760022, -0.02514614,\n",
       "       -0.0541257 , -0.06319906, -0.00054804, -0.00054804, -0.16369977,\n",
       "       -0.07402728])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b1f0af8-9c54-4ccb-abfa-482d83d6bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next query Random:  [0.5758351169093209, 0.7556730262590177, 0.7812975256644945]\n",
      "[1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Random search around an area restricted around $x$ = [0.57771284, 0.77197318]\n",
    "next_query_x1 = np.random.normal(0.57771284, scale = 0.01)\n",
    "next_query_x2 = np.random.normal(0.77197318, scale = 0.01)\n",
    "next_query_x3 = np.random.normal(0.77197318, scale = 0.01)\n",
    "print('Next query Random: ', [next_query_x1, next_query_x2, next_query_x3])\n",
    "\n",
    "# Using a restricted UCB\n",
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(X, Y)\n",
    "# to optimize the acquisition function, we will simply use gridsearch over a space of 10.000 gridpoints\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "x3 = np.linspace(0, 1, 100)\n",
    "X_grid = []\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        for k in range(len(x2)):\n",
    "            X_grid.append([x1[i], x2[j], x3[k]])\n",
    "\n",
    "X_grid = np.array(X_grid)\n",
    "mean, std = gpr.predict(X_grid, return_std = True)\n",
    "ucb = mean + 1.96 * std\n",
    "\n",
    "idx_max = np.argmax(ucb)\n",
    "next_query = X_grid[idx_max]\n",
    "print(next_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bdd3c2c-5852-4120-83f7-cec12adfb748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xdb13122\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values for minimizing adverse reaction:\n",
      "x1 = 0.9794082576780888, x2 = 0.905247530768202, x3 = 0.5394771512229771\n",
      "Minimum adverse reaction (closest to zero): 0.05993257949438238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Define the input and output data\n",
    "X = X\n",
    "Y = Y\n",
    "\n",
    "# Define the kernel and Gaussian Process with noise tolerance\n",
    "kernel = C(1.0, (1e-4, 1e4)) * RBF(length_scale=1.0, length_scale_bounds=(1e-3, 1e3))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1)\n",
    "gp.fit(X, Y)\n",
    "\n",
    "# Define the search space for the three variables (Real values based on range in X)\n",
    "space = [\n",
    "    Real(X[:, 0].min(), X[:, 0].max(), name=\"x1\"),\n",
    "    Real(X[:, 1].min(), X[:, 1].max(), name=\"x2\"),\n",
    "    Real(X[:, 2].min(), X[:, 2].max(), name=\"x3\")\n",
    "]\n",
    "\n",
    "# Define the objective function to minimize |adverse reaction| (bring it close to zero)\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    x_pred = np.array([[params[\"x1\"], params[\"x2\"], params[\"x3\"]]])\n",
    "    y_pred, _ = gp.predict(x_pred, return_std=True)\n",
    "    return abs(y_pred[0])  # Minimize the absolute value of the adverse reaction\n",
    "\n",
    "# Run Bayesian Optimization to minimize the absolute value of the adverse reaction\n",
    "result = gp_minimize(\n",
    "    objective, space, n_calls=60, random_state=0, acq_func=\"EI\", n_initial_points=5\n",
    ")\n",
    "\n",
    "# Extract the best parameters and minimum adverse reaction (closest to zero)\n",
    "best_x1, best_x2, best_x3 = result.x\n",
    "closest_to_zero_adverse_reaction = result.fun\n",
    "\n",
    "print(f\"Optimal values for minimizing adverse reaction:\")\n",
    "print(f\"x1 = {best_x1}, x2 = {best_x2}, x3 = {best_x3}\")\n",
    "print(f\"Minimum adverse reaction (closest to zero): {closest_to_zero_adverse_reaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f9d3e-f451-434e-91e9-fe258c24b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the input and output data\n",
    "X = X\n",
    "Y = Y\n",
    "# Step 1: Fit a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X, Y)\n",
    "\n",
    "# Step 2: Define the objective function to minimize\n",
    "def objective_function(x):\n",
    "    x = np.array(x).reshape(1, -1)  # Reshape x to fit the model input shape\n",
    "    y_pred = linear_model.predict(x)[0]  # Predict output using linear model\n",
    "    return abs(y_pred)  # Use absolute value to bring prediction closer to zero\n",
    "\n",
    "# Step 3: Use Bayesian optimization to find the optimal values of x1, x2, and x3\n",
    "# Define the bounds for x1, x2, and x3 (based on observed ranges in the data)\n",
    "space = [\n",
    "    Real(0, 1, name='x1'),\n",
    "    Real(0, 1, name='x2'),\n",
    "    Real(0, 1, name='x3')\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(objective_function, space, n_calls=50, random_state=0)\n",
    "\n",
    "# Extract optimal values for x1, x2, x3 and the minimum objective function value\n",
    "optimal_x1, optimal_x2, optimal_x3 = result.x\n",
    "optimal_y = linear_model.predict([[optimal_x1, optimal_x2, optimal_x3]])[0]\n",
    "\n",
    "print(\"Optimal x1:\", optimal_x1)\n",
    "print(\"Optimal x2:\", optimal_x2)\n",
    "print(\"Optimal x3:\", optimal_x3)\n",
    "print(\"Predicted Y for optimal x1, x2, x3:\", optimal_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a6447-0afd-4f09-8c04-750873cc10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the convergence of the optimization process\n",
    "plt.plot(result.func_vals, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective Function Value (|Y|)\")\n",
    "plt.title(\"Convergence of Bayesian Optimization for Linear Regression\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9fea25-4c97-4356-9841-cd0feff18096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create partial dependency plots for each variable\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# For each variable, fix the other two at their mean values\n",
    "x_means = np.mean(X, axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    # Vary only the i-th variable over its observed range\n",
    "    x_varied = np.linspace(X[:, i].min(), X[:, i].max(), 100)\n",
    "    X_plot = np.tile(x_means, (100, 1))  # Start with all features at mean\n",
    "    X_plot[:, i] = x_varied  # Vary only the i-th feature\n",
    "    \n",
    "    # Predict output for each value of the i-th variable\n",
    "    Y_pred = linear_model.predict(X_plot)\n",
    "    \n",
    "    # Plot the relationship between the i-th variable and the prediction\n",
    "    axs[i].plot(x_varied, Y_pred, label=f\"Variable {i+1}\")\n",
    "    axs[i].set_xlabel(f\"X{i+1}\")\n",
    "    axs[i].set_ylabel(\"Predicted Y\")\n",
    "    axs[i].set_title(f\"Effect of Variable {i+1} on Y\")\n",
    "    axs[i].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ace3f-c723-4f52-9e07-e4924ea02e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define the input and output data\n",
    "X = X\n",
    "Y = Y\n",
    "# Step 1: Fit the polynomial regression model\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, Y)\n",
    "\n",
    "# Step 2: Define the objective function to minimize (or bring to zero)\n",
    "def objective_function(x):\n",
    "    x_poly = poly.transform([x])  # Transform input x to polynomial features\n",
    "    y_pred = poly_model.predict(x_poly)[0]  # Predict output using polynomial model\n",
    "    return abs(y_pred)  # Use absolute value to bring prediction closer to zero\n",
    "\n",
    "# Step 3: Use Bayesian optimization to find the optimal values of x1, x2, and x3\n",
    "from skopt.space import Real\n",
    "\n",
    "# Define the bounds for x1, x2, and x3 (based on observed ranges in the data)\n",
    "space = [\n",
    "    Real(0, 1, name='x1'),\n",
    "    Real(0, 1, name='x2'),\n",
    "    Real(0, 1, name='x3')\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(objective_function, space, n_calls=50, random_state=0)\n",
    "\n",
    "# Optimal values for x1, x2, x3 and the minimum objective function value\n",
    "optimal_x1, optimal_x2, optimal_x3 = result.x\n",
    "optimal_y = poly_model.predict(poly.transform([[optimal_x1, optimal_x2, optimal_x3]]))[0]\n",
    "\n",
    "print(\"Optimal x1:\", optimal_x1)\n",
    "print(\"Optimal x2:\", optimal_x2)\n",
    "print(\"Optimal x3:\", optimal_x3)\n",
    "print(\"Predicted Y for optimal x1, x2, x3:\", optimal_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd75b6-a448-4c3d-8901-b173c6ddaeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the convergence of the optimization process\n",
    "plt.plot(result.func_vals, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective Function Value (|Y|)\")\n",
    "plt.title(\"Convergence of Bayesian Optimization\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c2bbb-82a5-4324-802a-4a18d60f71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partial dependency plots for each variable\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Mean values for the other variables\n",
    "x_means = np.mean(X, axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    # Vary only the i-th variable over its observed range\n",
    "    x_varied = np.linspace(X[:, i].min(), X[:, i].max(), 100)\n",
    "    X_plot = np.tile(x_means, (100, 1))  # Start with all features at mean\n",
    "    X_plot[:, i] = x_varied  # Vary only the i-th feature\n",
    "    \n",
    "    # Transform with polynomial features\n",
    "    X_plot_poly = poly.transform(X_plot)\n",
    "    \n",
    "    # Predict output for each value of the i-th variable\n",
    "    Y_pred = poly_model.predict(X_plot_poly)\n",
    "    \n",
    "    # Plot the relationship between the i-th variable and the prediction\n",
    "    axs[i].plot(x_varied, Y_pred, label=f\"Variable {i+1}\")\n",
    "    axs[i].set_xlabel(f\"X{i+1}\")\n",
    "    axs[i].set_ylabel(\"Predicted Y\")\n",
    "    axs[i].set_title(f\"Effect of Variable {i+1} on Y (Polynomial)\")\n",
    "    axs[i].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d8a77-5c5e-42e3-93f6-b95b284edaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
